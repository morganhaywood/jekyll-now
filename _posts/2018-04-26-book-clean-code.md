---
layout: post
title: Book&#58; Clean Code
tags:
  - learnings
  - books
---

This is a collation of my thoughts on the _Clean Code_ book. It is aggregated from my weekly reviews.

The forward to this book discussed the 5S principles (seiri (整理), seiton (整頓), seiso (清楚), seiketsu (清潔) and shitsuke (躾)) which made a lot of sense to me as principles for writing good code (although I found the explanation in the Japanese wikipedia was better than the one in the book :joy: 
I think Japanese concepts just make more sense in Japanese).

Chapter 1 discussed different definitions of “clean code”. The key points I took out of this were: bad code always slows you down, and begets more bad code; you can, should and have to fight to implement good code despite deadlines; 
clean code does one thing well; it is clear, easy to maintain and testable; we should aim to reduce duplication and use simple abstractions; work with your language, rather than forcing into something it’s not; write readable code; 
and always leave the code base cleaner than when you found it.

Chapter 2 discussed choosing names. The core of this was to make them as clear, intention-revealing and easy to use as possible. It also talked about avoiding encoding (including the implementation type in names), being consistent in name conventions, and giving context via classes etc in preference to prefixes. 
In short, your names should help make your code as easy to read, work with and refactor as possible.

Chapter 3 covered functions. Functions should be small, doing only one thing, use only one level of abstraction, have a descriptive name, have no side effects, and have as few arguments as possible. Long switch or if/else statements should generally be replaced by polymorphism (with the one remaining buried in a factory). It is better to have explicit outputs than output arguments, and exceptions should be used in preference to error codes. The contents of each part of a try/catch block should generally be their own method.

Chapter 4 covered comments. The main thrust was that comments should be avoided as much as possible, since they easily become out of date or misleading. It is generally better to write self-documenting code, and use comments only as a last resort (eg. to clarify working around code you cannot alter, TODOs, Javadocs for public APIs, warning of non-obvious consequences, etc).

Chapter 5 discussed formatting. It emphasised readability and consistency, especially when working as part of a team (since the whole team needs to use the same standards). I think the most interesting point it made was that code should be organised like a newspaper article, with the broad overview at the top and the nitty-gritty details at the bottom and a logical flow of information in between.

Chapter 6 talked about objects and data structures. I haven’t really thought about this topic before, so it was quite interesting. The main argument was that the two are opposites - objects expose functions which act on their data (but hide the data itself) while data structures expose their data but have no meaningful methods. This means that objects let you add new classes easily but make it difficult to add functions, and vice versa for data structures. Hybrids tend to have the worst of both worlds, so you should carefully and deliberately choose which you are going to use for each class.

Chapter 7 discussed how exceptions are preferable to returning error codes, since they allow more flexibility for when and how they are handled. It also talked about the importance of ensuring that your exceptions provide enough context, without having too many different types (which must be handled separately). It suggested encapsulating exceptional, but correct behaviour in special case objects rather than using exceptions, and why to avoid nulls where possible.

Chapter 8 discussed the use of boundaries, in particular between your system and 3rd party code. It recommended wrapping calls to 3rd party APIs (or even built-in, which may change) in your own class, so that if or when these change you only need to modify that single adapter class. This also makes testing easier, since you can easily create a test double for the adapter class which does not use the 3rd party code. Finally, it suggested testing the 3rd party API in much the same way you would your own code. This allows you to learn the new API, but later will also assist in verifying that a new version of the API is compatible with your application (or what you need to change).

Chapter 9 advocated that tests need to be maintained as well as the rest of your code. However, since efficiency is less of a concern, you should prioritise readability over efficiency (within reason, since your tests still need to run fast enough to be usable in a pipeline etc). It suggested writing functions within the test code on top your API when tests need to do extensive setup or other repeated calls, to make them more readable (e.g. `makePages(1,2,3,4,5)` to replace `book.addPage(1, whitePaper); book.addPage(2, whitePaper);...`). Each test should deal with only one concept, and minimise the number of asserts needed to test that concept. Finally, it discussed the need for tests to be F.I.R.S.T (fast, independent, repeatable, self-validating, and timely).  
When I looked at my tests for the tic tac toe kata, I felt that I had done fairly well with the recommendations for testing discussed above, except for the repeated calls during setup. I therefore went through and made changes based on the suggestions in Clean Code. I think that this was a good exercise, and definitely demonstrated how it can improved readability.

Chapter 10 discussed how classes should be organised. Variables should generally be public-static, then private-static, then private (since there is generally no reason to have public variables). Functions should follow a similar scheme: public first, but private methods should follow the public method that calls them rather than all being grouped at the end. Protected should generally only be used if absolutely necessary for testing.  
Classes should be as small as possible, and have only a single responsibility. Tied to this, they should also be cohesive, in that all the methods use most (if not all) of the same variables. When a class loses these properties, it should be split into two (or more) classes. Having many seperate, small classes means that each class will only have **one** reason to change. Thus changes won't break existing code (or as little exiting code as possible). This conforms to the open-closed principle: classes should be open for extension but closed for modification. In general, you should therefore be dependent upon interfaces rather than concrete classes (i.e. use the dependency inversion principle).

Chapter 11 examined systems. It explained the importance of having a globally consistent strategy for set up and instantiation. E.g. put all setup into main, use abstract factories, or use dependency injection. This is in contrast to e.g. using lazy initiation, where new objects are created on the fly when they become necessary. Separating these concerns allows for better incremental growth and easier testing. One way to get around many of these issues is to use a minimally-invasive aspect-oriented framework, which as the name suggests will handle certain concerns by aspect (e.g. instantiation). On a slightly different tack, this chapter also advocated doing **some** up-front design, but only the minimum necessary. In general decisions should be postponed until the last possible moment, so that they are made with the most possible information. Finally, architecture should not be invasive; it should help your code be clean, not take it over.

Chapter 12 discusses how simple, well-written code tends to be clean naturally. Specifically, if you follow the four rules of simple design then it almost unavoidable to end up with clean code. Rule 1 is to run all the tests, and easily testable code tends to be clean. A good test suite also makes refactoring easier, which leads to cleaner code. Rule 2 is to have no (or minimal) duplication, which removes work, risk and complexity. Template methods are a good way to do this; you implement all the common parts (sub-methods), and leave the variable section (sub-method) abstract, then sub-class it with concrete implementations. Rule 3 (express the intent of the programmer) naturally leads to meaningful names, small classes and standard nomenclature. Finally there is rule 4: minimise the number of classes and methods. It must be kept in mind that the rules are ordered, and therefore this is the lowest priority. It is bad to have too many tiny classes, but at the same time it is worse to have one huge one.

Chapter 13 covers (some of) concurrency. It is a very long chapter, and expected from the complexity of the subject. Concurrency decouples the **what** from the **when**. This can improve structure and throughput, but also introduces complexity which can do more harm than good. There are four basic principles to keep in mind when working with concurrency: the single responsibility principle (concurrency is one responsibility); to limit the scope of data; to use copies of data; and that threads should be as independent as possible. Other things to keep in mind include: understand your language's standard library an work with it; learn common execution models and how to solve the problems inherent in them (e.g. producer-consumer, readers-writers, dining philosophers); only have one synchronised method per class (use a client-based lock, server-based lock, or adapted server to achieve this if necessary); keep synchronised sections as small as possible, since these are bottlenecks; shutting down is very difficult, so if it's necessary then plan early; treat any unusual bugs or failures (especially sporadic ones) as threading issues; run your tests with many threads, on many OS and in many configurations (e.g. using jiggling); and keep your threaded and non-threaded code seperate and pluggable so that each can be tested independently of the other.

Chapter 14 is a case study showing how successive refinement can lead from a first draft of a program to a cleanly-written program. Rough drafts are necessary, but once you have enough information to understand what the design **should** be, but before your program gets too big to fix, you should stop adding features and take the time to clean what you have done. To do this you need to make incremental changes that move towards a better structure, but don't break the code. Having a test suite helps with this, since you can ensure that the program still works by checking that the tests pass. In general this sort of refactoring is a long process of splitting out one thing at a time (e.g. a new class, then gradually turning that new class into an interface and sub-class structure). Sometimes there is no **perfect** solution though, and you have to compromise.

Chapter 15 was a case-study of tidying up a JUnit class. There were a few points to come out of this. Refactoring is an iterative process; you may well undo a refactoring you've just done. You should write your code so that temporal coupling are explicit (e.g. have the second method take the output of the first). Choose whether to have variables be 0- or 1-based depending on where the +/-1s are the most readable. Refactoring can help expose useless statements. Group functions together based on their purpose (e.g. analysis vs formatting). 

Chapter 16 was a case-study of refactoring the `SerialDate` class. This was far more extensive than the chapter 15 case-study. The first thing to do before refactoring is to ensure that there is sufficient test coverage, and that all the tests pass.Then you can being the refactoring process, running the tests after each step. Comments should not include the change history, or html formatting, and should provide additional information; delete any unnecessary comments. `Enums` are usually better than constants, especially since they can include functions (e.g. for parsing). The same goes for things like switch statements. Variables and methods should be kept in the class that actually uses them; things which are only used in derivatives should not be in the base class, and things which need no knowledge of the derivatives should be in the base class. Base classes should not know anything about their derivatives. E.g. abstract factories can be used to maintain this. Things should be `private` by default, and only `protected` or `public` where necessary. It's better to have two separate functions than to pass flags, especially if it's just for formatting. Good naming and temporary, intermediate variables help to explain methods. Methods which are only used by the test suite can probably be deleted. Make logical dependencies clear through the structure of the code. `Enums`, and `static` variables and methods, can usually be moved into seperate utility classes. Abstract methods should be at the top of the class. 

Chapter 17 contained a long list of smells and heuristics:  
**Comments** should only hold information which is necessary and cannot be found elsewhere, and should be short and well-written. Code should not be commented out; it is better to delete it and use the source control system if you ever need it back.  
The **environment** should be a single step to build, and a single step to test.  
**Functions** should have as few arguments as possible, should not use output arguments, and not use flag arguments. They should do one thing, and use one level of abstraction. Uncalled functions should be deleted.  
**Names** should be clear and meaningful, and use the right level of abstraction. They should be unambiguous, and follow any standards or existing nomenclature. They should indicate any side-effects. Names should not encode type or scope. All things should do what they say on the tin.  
**Tests** should cover all conditions and validate all calculations. Coverage tools are useful for indicating where more tests are needed. Trivial tests are still worth writing for documentation. You should still write tests where there are ambiguities; you can `@Ignore` them or comment them out, but they will help document where clarification is needed. Always test boundaries, and write extra tests in code close to where you've found a bug; these areas are prone to error. Patterns of failure are useful for finding bugs; design or structure your tests with this in mind. Finally, tests must be as fast as possible to run.  
**Java** should import packages in preference to classes. Classes should not inherit just to access constants, and should use enums in preference to constants anyway.  
In **general** should try to only use one language per source file as much as possible. Implement obvious behaviour, which your users will expect. Avoid overriding safeties. Don't duplicate code or functionality. Group levels of abstraction. Don't couple base classes to their derivatives, or anything that doesn't need to be coupled. Keep interfaces and methods small. Delete code which is never called, and remove clutter. Order variables and private functions near to where they are first used, and be consistent. Functions should not be overly interested in the internals of other classes. Don't obscure intent, and put responsibilities where they are most expected. Err towards non-static functions, and carefully check that all static functions do need to be static. Use intermediate variables to explain calculations and functions. Make sure you fully understand your algorithm, and can verify its correctness. Make logical or temporal dependencies physical through code design. Use polymorphism over selectors; you should only need one selector of each type (to set up the polymorphism). Follow common conventions, especially within the team, and enforce these using code structure where possible. Use constants over magic numbers. Deal with edge cases and eliminate any possible imprecisions. Encapsulate condition checks, especially boundary conditions, and express these as positives where possible. Make sure that your structural choices are deliberate, and that your reasoning is expressed in the structure. Keep all configuration in one place at a high level, even if you expect it to never change, so that it is clear where these defaults are coming from. Only call methods on your variables, not your variables' variables; you shouldn't need to transverse project structure.  
Despite all the above rules however, this chapter makes the point that the values behind them are more important than the rules themselves.

Appendix A follows on from chapter 13 in discussing concurrency. Adding threads won't improve performance if the action is processor-bound (since it won't improve your processor!) but will if it is I/O bound (e.g. must wait on a response from a server). If used appropriately, threading can increase throughput by overlapping processor-bound and I/O-bound operations. There are **many** paths of execution (lines of byte code, per thread, with all possible context switches). Pay attention to which operations are atomic, and use guards when necessary. Java's executor framework will manage thread pools and provides other features such as callables and futures.  
Using non-blocking classes is preferable, since they improve throughput by not always acquiring a lock. Some classes however are inherently not thread-safe, even if their individual methods are, because dependencies between methods can break concurrent code. In this situation there are three options: tolerate the failure, client-based locking, and server-based locking. Tolerating the failure tends to be sloppy. Client-based locking leads to duplication of code, and risks a difficult-to-trace bug if any one piece of code forgets to lock or unlock. Server-based locking is therefore preferred; it reduces repeated code, allows for better performance, reduces the possibility of error, enforces a single policy, and reduces the scope of shared variables. If you don't own the server code, use an adapter or switch to a thread-safe server (e.g. thread-safe collections with extended interfaces).  
Deadlocks occur when four conditions are all present: mutual exclusion, where threads cannot concurrently use a limited resource (e.g. a DB connection); lock and wait, where threads wait for resources with some locked, and do not release them while waiting; no preemption, where threads cannot ask others to release resources; and circular wait, where two threads may each be waiting on a resource held by the other. Since all four are required for a deadlock, it can be prevented by breaking one. Mutual exclusion **can** be broken by allowing simultaneous use, having more copies of a resource than threads, or checking all necessary resources are free before locking any, but these often aren't possible or practical. Lock and wait can be prevented by having threads release all of their resources if they cannot acquire one. This is better than nothing, but can lead to starvation (where a thread is unable to acquire its resources) or livelock (where threads continuously acquire and release resources in lock-step). Preemption can be allowed; if a resource is busy, the thread wanting it will ask its owner for it, and if the owner is waiting for another resource then it will release it. This has similar considerations to breaking lock and wait; it requires less restarting of threads' routines, but is much more complex. Finally, circular wait can be prevented by having all threads agree upon an order in which to acquire resources. However this can lead to longer locks, and is sometimes not possible. 
In order to preserve single responsibly, thread management should be kept separate from other concerns. This also helps enormously with debugging; it is hard enough to track down thread-related errors, without having to also try to solve logic etc. errors at the same time! This is because concurrent code can be very difficult to test. Even if you set up tests which have the potential to find thread-related errors (e.g. two threads accessing a non-thread-safe method) the bug may only occur once in several thousand runs; how can you run the tests enough to be sure you have caught any errors, but not so much it becomes impractical? One strategy is to write tests which can be tuned, and then run these frequently with random changes to the tuning variables (e.g. on a test server). You could also run tests continuously on every target platform, or run the tests with varying simulated loads. The best option, however, is to use a tool which will instrument your tests to cause thread bugs more often.

_Clean Code_ has been an interesting read. As it stated, I think that the values are far more important than the rules it expounds. We should all strive for well-designed, easily understandable, and provably correct code. A lot of this book however is either Java-centric or personal preference. For example, many of the design principles are simply not applicable (or will make your code far **less** clean) outside of the object-oriented world. And I don't agree with everything in it (e.g. some of the **lengthy** method names I find far less clear than a shorter, less precise one). On the whole though, I think that is a useful window into **one** method of working towards good code, and its core values should be taken to heart.
